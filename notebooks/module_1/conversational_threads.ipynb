{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conversational Threads\n",
                "\n",
                "## What I Learned\n",
                "I learned how to group traces into threads using a unique thread ID, which helps keep all related traces from a conversation together. This feature is useful for tracking chat sessions and multi-turn dialogue workflows.\n",
                "\n",
                "## Changes in Code\n",
                "My main changes involved generating a new UUID for thread metadata and using it to organize runs as conversations. I demonstrated the feature by running the notebook multiple times and included an example where retrieval did not find the requested item."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import uuid\n",
                "from langsmith import traceable\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "# Generate a thread ID for this conversation\n",
                "thread_id = str(uuid.uuid4())\n",
                "\n",
                "@traceable(\n",
                "    run_type=\"chain\",\n",
                "    metadata={\"thread_id\": thread_id}\n",
                ")\n",
                "def chat_turn(message: str, history: list) -> str:\n",
                "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
                "    full_conversation = history + [{\"role\": \"user\", \"content\": message}]\n",
                "    response = llm.invoke(full_conversation)\n",
                "    return response.content\n",
                "\n",
                "# Simulate a conversation\n",
                "history = []\n",
                "response1 = chat_turn(\"Hello! What is LangSmith?\", history)\n",
                "print(f\"Turn 1: {response1}\")\n",
                "\n",
                "history.append({\"role\": \"user\", \"content\": \"Hello! What is LangSmith?\"})\n",
                "history.append({\"role\": \"assistant\", \"content\": response1})\n",
                "\n",
                "response2 = chat_turn(\"How does it help with debugging?\", history)\n",
                "print(f\"Turn 2: {response2}\")\n",
                "\n",
                "print(f\"\\nThread ID: {thread_id}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Utility functions\n",
                "def format_messages(messages: list) -> str:\n",
                "    \"\"\"Format conversation messages for display\"\"\"\n",
                "    return \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in messages])\n",
                "\n",
                "def extract_user_intent(message: str) -> str:\n",
                "    \"\"\"Extract user intent from message\"\"\"\n",
                "    # Simple keyword matching\n",
                "    if \"help\" in message.lower():\n",
                "        return \"help_request\"\n",
                "    elif \"?\" in message:\n",
                "        return \"question\"\n",
                "    else:\n",
                "        return \"statement\""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}